{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train),(X_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 784)\n",
    "X_train.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test.reshape(X_test.shape[0], 784)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "scaler.fit(X_test)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(784,)))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=SGD(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "modelpath = \"./model_optimization/mnist_MLP.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1459/1500 [============================>.] - ETA: 0s - loss: 0.4376 - accuracy: 0.8841\n",
      "Epoch 1: val_loss improved from inf to 0.40489, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 730us/step - loss: 0.4377 - accuracy: 0.8839 - val_loss: 0.4049 - val_accuracy: 0.8945\n",
      "Epoch 2/100\n",
      "1485/1500 [============================>.] - ETA: 0s - loss: 0.4330 - accuracy: 0.8849\n",
      "Epoch 2: val_loss improved from 0.40489 to 0.40099, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 709us/step - loss: 0.4332 - accuracy: 0.8847 - val_loss: 0.4010 - val_accuracy: 0.8948\n",
      "Epoch 3/100\n",
      "1412/1500 [===========================>..] - ETA: 0s - loss: 0.4296 - accuracy: 0.8850\n",
      "Epoch 3: val_loss improved from 0.40099 to 0.39737, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 710us/step - loss: 0.4290 - accuracy: 0.8856 - val_loss: 0.3974 - val_accuracy: 0.8956\n",
      "Epoch 4/100\n",
      "1493/1500 [============================>.] - ETA: 0s - loss: 0.4252 - accuracy: 0.8863\n",
      "Epoch 4: val_loss improved from 0.39737 to 0.39393, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 719us/step - loss: 0.4251 - accuracy: 0.8865 - val_loss: 0.3939 - val_accuracy: 0.8964\n",
      "Epoch 5/100\n",
      "1471/1500 [============================>.] - ETA: 0s - loss: 0.4218 - accuracy: 0.8870\n",
      "Epoch 5: val_loss improved from 0.39393 to 0.39075, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 718us/step - loss: 0.4214 - accuracy: 0.8871 - val_loss: 0.3908 - val_accuracy: 0.8968\n",
      "Epoch 6/100\n",
      "1424/1500 [===========================>..] - ETA: 0s - loss: 0.4175 - accuracy: 0.8879\n",
      "Epoch 6: val_loss improved from 0.39075 to 0.38780, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 704us/step - loss: 0.4179 - accuracy: 0.8875 - val_loss: 0.3878 - val_accuracy: 0.8971\n",
      "Epoch 7/100\n",
      "1482/1500 [============================>.] - ETA: 0s - loss: 0.4146 - accuracy: 0.8882\n",
      "Epoch 7: val_loss improved from 0.38780 to 0.38502, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 720us/step - loss: 0.4146 - accuracy: 0.8882 - val_loss: 0.3850 - val_accuracy: 0.8979\n",
      "Epoch 8/100\n",
      "1493/1500 [============================>.] - ETA: 0s - loss: 0.4113 - accuracy: 0.8892\n",
      "Epoch 8: val_loss improved from 0.38502 to 0.38225, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 711us/step - loss: 0.4115 - accuracy: 0.8891 - val_loss: 0.3822 - val_accuracy: 0.8988\n",
      "Epoch 9/100\n",
      "1467/1500 [============================>.] - ETA: 0s - loss: 0.4088 - accuracy: 0.8896\n",
      "Epoch 9: val_loss improved from 0.38225 to 0.37970, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 723us/step - loss: 0.4086 - accuracy: 0.8897 - val_loss: 0.3797 - val_accuracy: 0.8990\n",
      "Epoch 10/100\n",
      "1439/1500 [===========================>..] - ETA: 0s - loss: 0.4058 - accuracy: 0.8905\n",
      "Epoch 10: val_loss improved from 0.37970 to 0.37729, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 728us/step - loss: 0.4058 - accuracy: 0.8906 - val_loss: 0.3773 - val_accuracy: 0.8992\n",
      "Epoch 11/100\n",
      "1476/1500 [============================>.] - ETA: 0s - loss: 0.4031 - accuracy: 0.8912\n",
      "Epoch 11: val_loss improved from 0.37729 to 0.37500, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 714us/step - loss: 0.4031 - accuracy: 0.8912 - val_loss: 0.3750 - val_accuracy: 0.9000\n",
      "Epoch 12/100\n",
      "1495/1500 [============================>.] - ETA: 0s - loss: 0.4004 - accuracy: 0.8918\n",
      "Epoch 12: val_loss improved from 0.37500 to 0.37286, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 706us/step - loss: 0.4006 - accuracy: 0.8918 - val_loss: 0.3729 - val_accuracy: 0.9001\n",
      "Epoch 13/100\n",
      "1482/1500 [============================>.] - ETA: 0s - loss: 0.3985 - accuracy: 0.8923\n",
      "Epoch 13: val_loss improved from 0.37286 to 0.37073, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 722us/step - loss: 0.3982 - accuracy: 0.8923 - val_loss: 0.3707 - val_accuracy: 0.9004\n",
      "Epoch 14/100\n",
      "1492/1500 [============================>.] - ETA: 0s - loss: 0.3961 - accuracy: 0.8929\n",
      "Epoch 14: val_loss improved from 0.37073 to 0.36879, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 745us/step - loss: 0.3959 - accuracy: 0.8930 - val_loss: 0.3688 - val_accuracy: 0.9005\n",
      "Epoch 15/100\n",
      "1492/1500 [============================>.] - ETA: 0s - loss: 0.3936 - accuracy: 0.8929\n",
      "Epoch 15: val_loss improved from 0.36879 to 0.36690, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 707us/step - loss: 0.3936 - accuracy: 0.8930 - val_loss: 0.3669 - val_accuracy: 0.9008\n",
      "Epoch 16/100\n",
      "1426/1500 [===========================>..] - ETA: 0s - loss: 0.3905 - accuracy: 0.8939\n",
      "Epoch 16: val_loss improved from 0.36690 to 0.36504, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 692us/step - loss: 0.3915 - accuracy: 0.8934 - val_loss: 0.3650 - val_accuracy: 0.9013\n",
      "Epoch 17/100\n",
      "1429/1500 [===========================>..] - ETA: 0s - loss: 0.3895 - accuracy: 0.8943\n",
      "Epoch 17: val_loss improved from 0.36504 to 0.36331, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 703us/step - loss: 0.3895 - accuracy: 0.8943 - val_loss: 0.3633 - val_accuracy: 0.9017\n",
      "Epoch 18/100\n",
      "1442/1500 [===========================>..] - ETA: 0s - loss: 0.3873 - accuracy: 0.8949\n",
      "Epoch 18: val_loss improved from 0.36331 to 0.36172, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 696us/step - loss: 0.3875 - accuracy: 0.8947 - val_loss: 0.3617 - val_accuracy: 0.9018\n",
      "Epoch 19/100\n",
      "1449/1500 [===========================>..] - ETA: 0s - loss: 0.3861 - accuracy: 0.8945\n",
      "Epoch 19: val_loss improved from 0.36172 to 0.36006, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 734us/step - loss: 0.3856 - accuracy: 0.8948 - val_loss: 0.3601 - val_accuracy: 0.9023\n",
      "Epoch 20/100\n",
      "1460/1500 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8956\n",
      "Epoch 20: val_loss improved from 0.36006 to 0.35851, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 721us/step - loss: 0.3838 - accuracy: 0.8957 - val_loss: 0.3585 - val_accuracy: 0.9028\n",
      "Epoch 21/100\n",
      "1461/1500 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8959\n",
      "Epoch 21: val_loss improved from 0.35851 to 0.35703, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 717us/step - loss: 0.3820 - accuracy: 0.8962 - val_loss: 0.3570 - val_accuracy: 0.9031\n",
      "Epoch 22/100\n",
      "1423/1500 [===========================>..] - ETA: 0s - loss: 0.3813 - accuracy: 0.8967\n",
      "Epoch 22: val_loss improved from 0.35703 to 0.35566, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 704us/step - loss: 0.3803 - accuracy: 0.8967 - val_loss: 0.3557 - val_accuracy: 0.9030\n",
      "Epoch 23/100\n",
      "1454/1500 [============================>.] - ETA: 0s - loss: 0.3787 - accuracy: 0.8969\n",
      "Epoch 23: val_loss improved from 0.35566 to 0.35422, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 718us/step - loss: 0.3787 - accuracy: 0.8969 - val_loss: 0.3542 - val_accuracy: 0.9038\n",
      "Epoch 24/100\n",
      "1424/1500 [===========================>..] - ETA: 0s - loss: 0.3768 - accuracy: 0.8974\n",
      "Epoch 24: val_loss improved from 0.35422 to 0.35289, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 698us/step - loss: 0.3771 - accuracy: 0.8973 - val_loss: 0.3529 - val_accuracy: 0.9042\n",
      "Epoch 25/100\n",
      "1437/1500 [===========================>..] - ETA: 0s - loss: 0.3757 - accuracy: 0.8976\n",
      "Epoch 25: val_loss improved from 0.35289 to 0.35160, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 734us/step - loss: 0.3756 - accuracy: 0.8978 - val_loss: 0.3516 - val_accuracy: 0.9043\n",
      "Epoch 26/100\n",
      "1425/1500 [===========================>..] - ETA: 0s - loss: 0.3748 - accuracy: 0.8979\n",
      "Epoch 26: val_loss improved from 0.35160 to 0.35038, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 734us/step - loss: 0.3741 - accuracy: 0.8981 - val_loss: 0.3504 - val_accuracy: 0.9042\n",
      "Epoch 27/100\n",
      "1484/1500 [============================>.] - ETA: 0s - loss: 0.3731 - accuracy: 0.8984\n",
      "Epoch 27: val_loss improved from 0.35038 to 0.34913, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 720us/step - loss: 0.3727 - accuracy: 0.8985 - val_loss: 0.3491 - val_accuracy: 0.9046\n",
      "Epoch 28/100\n",
      "1425/1500 [===========================>..] - ETA: 0s - loss: 0.3716 - accuracy: 0.8984\n",
      "Epoch 28: val_loss improved from 0.34913 to 0.34799, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 740us/step - loss: 0.3713 - accuracy: 0.8988 - val_loss: 0.3480 - val_accuracy: 0.9046\n",
      "Epoch 29/100\n",
      "1465/1500 [============================>.] - ETA: 0s - loss: 0.3699 - accuracy: 0.8990\n",
      "Epoch 29: val_loss improved from 0.34799 to 0.34685, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 728us/step - loss: 0.3699 - accuracy: 0.8993 - val_loss: 0.3469 - val_accuracy: 0.9047\n",
      "Epoch 30/100\n",
      "1475/1500 [============================>.] - ETA: 0s - loss: 0.3684 - accuracy: 0.8993\n",
      "Epoch 30: val_loss improved from 0.34685 to 0.34574, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 713us/step - loss: 0.3686 - accuracy: 0.8993 - val_loss: 0.3457 - val_accuracy: 0.9057\n",
      "Epoch 31/100\n",
      "1471/1500 [============================>.] - ETA: 0s - loss: 0.3676 - accuracy: 0.8997\n",
      "Epoch 31: val_loss improved from 0.34574 to 0.34472, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 718us/step - loss: 0.3674 - accuracy: 0.8998 - val_loss: 0.3447 - val_accuracy: 0.9055\n",
      "Epoch 32/100\n",
      "1415/1500 [===========================>..] - ETA: 0s - loss: 0.3650 - accuracy: 0.9001\n",
      "Epoch 32: val_loss improved from 0.34472 to 0.34369, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 700us/step - loss: 0.3661 - accuracy: 0.9001 - val_loss: 0.3437 - val_accuracy: 0.9058\n",
      "Epoch 33/100\n",
      "1485/1500 [============================>.] - ETA: 0s - loss: 0.3652 - accuracy: 0.9000\n",
      "Epoch 33: val_loss improved from 0.34369 to 0.34264, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 712us/step - loss: 0.3649 - accuracy: 0.9001 - val_loss: 0.3426 - val_accuracy: 0.9066\n",
      "Epoch 34/100\n",
      "1495/1500 [============================>.] - ETA: 0s - loss: 0.3641 - accuracy: 0.9004\n",
      "Epoch 34: val_loss improved from 0.34264 to 0.34171, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 706us/step - loss: 0.3638 - accuracy: 0.9004 - val_loss: 0.3417 - val_accuracy: 0.9064\n",
      "Epoch 35/100\n",
      "1475/1500 [============================>.] - ETA: 0s - loss: 0.3632 - accuracy: 0.9007\n",
      "Epoch 35: val_loss improved from 0.34171 to 0.34076, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 767us/step - loss: 0.3626 - accuracy: 0.9008 - val_loss: 0.3408 - val_accuracy: 0.9068\n",
      "Epoch 36/100\n",
      "1492/1500 [============================>.] - ETA: 0s - loss: 0.3621 - accuracy: 0.9007\n",
      "Epoch 36: val_loss improved from 0.34076 to 0.33982, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 817us/step - loss: 0.3615 - accuracy: 0.9009 - val_loss: 0.3398 - val_accuracy: 0.9072\n",
      "Epoch 37/100\n",
      "1444/1500 [===========================>..] - ETA: 0s - loss: 0.3605 - accuracy: 0.9011\n",
      "Epoch 37: val_loss improved from 0.33982 to 0.33892, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 763us/step - loss: 0.3605 - accuracy: 0.9012 - val_loss: 0.3389 - val_accuracy: 0.9074\n",
      "Epoch 38/100\n",
      "1414/1500 [===========================>..] - ETA: 0s - loss: 0.3597 - accuracy: 0.9011\n",
      "Epoch 38: val_loss improved from 0.33892 to 0.33805, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 703us/step - loss: 0.3594 - accuracy: 0.9012 - val_loss: 0.3380 - val_accuracy: 0.9076\n",
      "Epoch 39/100\n",
      "1425/1500 [===========================>..] - ETA: 0s - loss: 0.3581 - accuracy: 0.9013\n",
      "Epoch 39: val_loss improved from 0.33805 to 0.33716, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 703us/step - loss: 0.3584 - accuracy: 0.9015 - val_loss: 0.3372 - val_accuracy: 0.9077\n",
      "Epoch 40/100\n",
      "1498/1500 [============================>.] - ETA: 0s - loss: 0.3574 - accuracy: 0.9016\n",
      "Epoch 40: val_loss improved from 0.33716 to 0.33636, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 741us/step - loss: 0.3574 - accuracy: 0.9015 - val_loss: 0.3364 - val_accuracy: 0.9075\n",
      "Epoch 41/100\n",
      "1462/1500 [============================>.] - ETA: 0s - loss: 0.3559 - accuracy: 0.9021\n",
      "Epoch 41: val_loss improved from 0.33636 to 0.33555, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 728us/step - loss: 0.3564 - accuracy: 0.9018 - val_loss: 0.3355 - val_accuracy: 0.9077\n",
      "Epoch 42/100\n",
      "1492/1500 [============================>.] - ETA: 0s - loss: 0.3557 - accuracy: 0.9019\n",
      "Epoch 42: val_loss improved from 0.33555 to 0.33476, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 713us/step - loss: 0.3554 - accuracy: 0.9020 - val_loss: 0.3348 - val_accuracy: 0.9079\n",
      "Epoch 43/100\n",
      "1433/1500 [===========================>..] - ETA: 0s - loss: 0.3548 - accuracy: 0.9025\n",
      "Epoch 43: val_loss improved from 0.33476 to 0.33404, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 736us/step - loss: 0.3545 - accuracy: 0.9024 - val_loss: 0.3340 - val_accuracy: 0.9078\n",
      "Epoch 44/100\n",
      "1488/1500 [============================>.] - ETA: 0s - loss: 0.3538 - accuracy: 0.9024\n",
      "Epoch 44: val_loss improved from 0.33404 to 0.33327, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 713us/step - loss: 0.3536 - accuracy: 0.9026 - val_loss: 0.3333 - val_accuracy: 0.9081\n",
      "Epoch 45/100\n",
      "1479/1500 [============================>.] - ETA: 0s - loss: 0.3524 - accuracy: 0.9026\n",
      "Epoch 45: val_loss improved from 0.33327 to 0.33252, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 748us/step - loss: 0.3527 - accuracy: 0.9025 - val_loss: 0.3325 - val_accuracy: 0.9086\n",
      "Epoch 46/100\n",
      "1454/1500 [============================>.] - ETA: 0s - loss: 0.3524 - accuracy: 0.9024\n",
      "Epoch 46: val_loss improved from 0.33252 to 0.33180, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 726us/step - loss: 0.3519 - accuracy: 0.9027 - val_loss: 0.3318 - val_accuracy: 0.9087\n",
      "Epoch 47/100\n",
      "1468/1500 [============================>.] - ETA: 0s - loss: 0.3503 - accuracy: 0.9032\n",
      "Epoch 47: val_loss improved from 0.33180 to 0.33108, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 939us/step - loss: 0.3510 - accuracy: 0.9028 - val_loss: 0.3311 - val_accuracy: 0.9092\n",
      "Epoch 48/100\n",
      "1425/1500 [===========================>..] - ETA: 0s - loss: 0.3497 - accuracy: 0.9030\n",
      "Epoch 48: val_loss improved from 0.33108 to 0.33041, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 808us/step - loss: 0.3502 - accuracy: 0.9032 - val_loss: 0.3304 - val_accuracy: 0.9093\n",
      "Epoch 49/100\n",
      "1434/1500 [===========================>..] - ETA: 0s - loss: 0.3502 - accuracy: 0.9030\n",
      "Epoch 49: val_loss improved from 0.33041 to 0.32976, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 701us/step - loss: 0.3494 - accuracy: 0.9032 - val_loss: 0.3298 - val_accuracy: 0.9087\n",
      "Epoch 50/100\n",
      "1471/1500 [============================>.] - ETA: 0s - loss: 0.3481 - accuracy: 0.9032\n",
      "Epoch 50: val_loss improved from 0.32976 to 0.32909, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 778us/step - loss: 0.3486 - accuracy: 0.9032 - val_loss: 0.3291 - val_accuracy: 0.9091\n",
      "Epoch 51/100\n",
      "1468/1500 [============================>.] - ETA: 0s - loss: 0.3477 - accuracy: 0.9034\n",
      "Epoch 51: val_loss improved from 0.32909 to 0.32847, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 725us/step - loss: 0.3478 - accuracy: 0.9035 - val_loss: 0.3285 - val_accuracy: 0.9095\n",
      "Epoch 52/100\n",
      "1441/1500 [===========================>..] - ETA: 0s - loss: 0.3482 - accuracy: 0.9032\n",
      "Epoch 52: val_loss improved from 0.32847 to 0.32781, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 745us/step - loss: 0.3470 - accuracy: 0.9036 - val_loss: 0.3278 - val_accuracy: 0.9101\n",
      "Epoch 53/100\n",
      "1445/1500 [===========================>..] - ETA: 0s - loss: 0.3465 - accuracy: 0.9035\n",
      "Epoch 53: val_loss improved from 0.32781 to 0.32722, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 801us/step - loss: 0.3463 - accuracy: 0.9038 - val_loss: 0.3272 - val_accuracy: 0.9096\n",
      "Epoch 54/100\n",
      "1467/1500 [============================>.] - ETA: 0s - loss: 0.3458 - accuracy: 0.9043\n",
      "Epoch 54: val_loss improved from 0.32722 to 0.32662, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 816us/step - loss: 0.3455 - accuracy: 0.9042 - val_loss: 0.3266 - val_accuracy: 0.9101\n",
      "Epoch 55/100\n",
      "1478/1500 [============================>.] - ETA: 0s - loss: 0.3450 - accuracy: 0.9041\n",
      "Epoch 55: val_loss improved from 0.32662 to 0.32604, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 715us/step - loss: 0.3448 - accuracy: 0.9042 - val_loss: 0.3260 - val_accuracy: 0.9103\n",
      "Epoch 56/100\n",
      "1484/1500 [============================>.] - ETA: 0s - loss: 0.3439 - accuracy: 0.9046\n",
      "Epoch 56: val_loss improved from 0.32604 to 0.32543, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 796us/step - loss: 0.3441 - accuracy: 0.9045 - val_loss: 0.3254 - val_accuracy: 0.9107\n",
      "Epoch 57/100\n",
      "1488/1500 [============================>.] - ETA: 0s - loss: 0.3433 - accuracy: 0.9049\n",
      "Epoch 57: val_loss improved from 0.32543 to 0.32487, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3434 - accuracy: 0.9048 - val_loss: 0.3249 - val_accuracy: 0.9107\n",
      "Epoch 58/100\n",
      "1479/1500 [============================>.] - ETA: 0s - loss: 0.3425 - accuracy: 0.9047\n",
      "Epoch 58: val_loss improved from 0.32487 to 0.32433, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 910us/step - loss: 0.3427 - accuracy: 0.9047 - val_loss: 0.3243 - val_accuracy: 0.9107\n",
      "Epoch 59/100\n",
      "1477/1500 [============================>.] - ETA: 0s - loss: 0.3418 - accuracy: 0.9049\n",
      "Epoch 59: val_loss improved from 0.32433 to 0.32379, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3421 - accuracy: 0.9049 - val_loss: 0.3238 - val_accuracy: 0.9108\n",
      "Epoch 60/100\n",
      "1476/1500 [============================>.] - ETA: 0s - loss: 0.3401 - accuracy: 0.9057\n",
      "Epoch 60: val_loss improved from 0.32379 to 0.32324, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3414 - accuracy: 0.9053 - val_loss: 0.3232 - val_accuracy: 0.9107\n",
      "Epoch 61/100\n",
      "1481/1500 [============================>.] - ETA: 0s - loss: 0.3404 - accuracy: 0.9053\n",
      "Epoch 61: val_loss improved from 0.32324 to 0.32269, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 944us/step - loss: 0.3408 - accuracy: 0.9055 - val_loss: 0.3227 - val_accuracy: 0.9111\n",
      "Epoch 62/100\n",
      "1435/1500 [===========================>..] - ETA: 0s - loss: 0.3398 - accuracy: 0.9059\n",
      "Epoch 62: val_loss improved from 0.32269 to 0.32219, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 950us/step - loss: 0.3401 - accuracy: 0.9056 - val_loss: 0.3222 - val_accuracy: 0.9110\n",
      "Epoch 63/100\n",
      "1431/1500 [===========================>..] - ETA: 0s - loss: 0.3392 - accuracy: 0.9060\n",
      "Epoch 63: val_loss improved from 0.32219 to 0.32167, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 858us/step - loss: 0.3395 - accuracy: 0.9058 - val_loss: 0.3217 - val_accuracy: 0.9112\n",
      "Epoch 64/100\n",
      "1498/1500 [============================>.] - ETA: 0s - loss: 0.3390 - accuracy: 0.9060\n",
      "Epoch 64: val_loss improved from 0.32167 to 0.32120, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 795us/step - loss: 0.3389 - accuracy: 0.9060 - val_loss: 0.3212 - val_accuracy: 0.9112\n",
      "Epoch 65/100\n",
      "1475/1500 [============================>.] - ETA: 0s - loss: 0.3385 - accuracy: 0.9061\n",
      "Epoch 65: val_loss improved from 0.32120 to 0.32071, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 842us/step - loss: 0.3383 - accuracy: 0.9061 - val_loss: 0.3207 - val_accuracy: 0.9113\n",
      "Epoch 66/100\n",
      "1440/1500 [===========================>..] - ETA: 0s - loss: 0.3371 - accuracy: 0.9066\n",
      "Epoch 66: val_loss improved from 0.32071 to 0.32021, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 787us/step - loss: 0.3377 - accuracy: 0.9063 - val_loss: 0.3202 - val_accuracy: 0.9115\n",
      "Epoch 67/100\n",
      "1418/1500 [===========================>..] - ETA: 0s - loss: 0.3359 - accuracy: 0.9068\n",
      "Epoch 67: val_loss improved from 0.32021 to 0.31977, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 743us/step - loss: 0.3371 - accuracy: 0.9064 - val_loss: 0.3198 - val_accuracy: 0.9115\n",
      "Epoch 68/100\n",
      "1471/1500 [============================>.] - ETA: 0s - loss: 0.3366 - accuracy: 0.9065\n",
      "Epoch 68: val_loss improved from 0.31977 to 0.31931, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 830us/step - loss: 0.3366 - accuracy: 0.9064 - val_loss: 0.3193 - val_accuracy: 0.9118\n",
      "Epoch 69/100\n",
      "1432/1500 [===========================>..] - ETA: 0s - loss: 0.3363 - accuracy: 0.9064\n",
      "Epoch 69: val_loss improved from 0.31931 to 0.31884, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 787us/step - loss: 0.3360 - accuracy: 0.9067 - val_loss: 0.3188 - val_accuracy: 0.9116\n",
      "Epoch 70/100\n",
      "1432/1500 [===========================>..] - ETA: 0s - loss: 0.3362 - accuracy: 0.9066\n",
      "Epoch 70: val_loss improved from 0.31884 to 0.31839, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 785us/step - loss: 0.3354 - accuracy: 0.9067 - val_loss: 0.3184 - val_accuracy: 0.9118\n",
      "Epoch 71/100\n",
      "1445/1500 [===========================>..] - ETA: 0s - loss: 0.3362 - accuracy: 0.9065\n",
      "Epoch 71: val_loss improved from 0.31839 to 0.31798, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 771us/step - loss: 0.3349 - accuracy: 0.9071 - val_loss: 0.3180 - val_accuracy: 0.9113\n",
      "Epoch 72/100\n",
      "1438/1500 [===========================>..] - ETA: 0s - loss: 0.3359 - accuracy: 0.9067\n",
      "Epoch 72: val_loss improved from 0.31798 to 0.31753, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 746us/step - loss: 0.3344 - accuracy: 0.9072 - val_loss: 0.3175 - val_accuracy: 0.9120\n",
      "Epoch 73/100\n",
      "1429/1500 [===========================>..] - ETA: 0s - loss: 0.3326 - accuracy: 0.9076\n",
      "Epoch 73: val_loss improved from 0.31753 to 0.31711, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 751us/step - loss: 0.3339 - accuracy: 0.9073 - val_loss: 0.3171 - val_accuracy: 0.9119\n",
      "Epoch 74/100\n",
      "1430/1500 [===========================>..] - ETA: 0s - loss: 0.3334 - accuracy: 0.9075\n",
      "Epoch 74: val_loss improved from 0.31711 to 0.31669, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 741us/step - loss: 0.3333 - accuracy: 0.9077 - val_loss: 0.3167 - val_accuracy: 0.9121\n",
      "Epoch 75/100\n",
      "1456/1500 [============================>.] - ETA: 0s - loss: 0.3321 - accuracy: 0.9076\n",
      "Epoch 75: val_loss improved from 0.31669 to 0.31627, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 777us/step - loss: 0.3328 - accuracy: 0.9074 - val_loss: 0.3163 - val_accuracy: 0.9122\n",
      "Epoch 76/100\n",
      "1496/1500 [============================>.] - ETA: 0s - loss: 0.3326 - accuracy: 0.9079\n",
      "Epoch 76: val_loss improved from 0.31627 to 0.31588, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 744us/step - loss: 0.3323 - accuracy: 0.9079 - val_loss: 0.3159 - val_accuracy: 0.9123\n",
      "Epoch 77/100\n",
      "1486/1500 [============================>.] - ETA: 0s - loss: 0.3314 - accuracy: 0.9079\n",
      "Epoch 77: val_loss improved from 0.31588 to 0.31549, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 813us/step - loss: 0.3318 - accuracy: 0.9078 - val_loss: 0.3155 - val_accuracy: 0.9125\n",
      "Epoch 78/100\n",
      "1497/1500 [============================>.] - ETA: 0s - loss: 0.3316 - accuracy: 0.9078\n",
      "Epoch 78: val_loss improved from 0.31549 to 0.31509, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3313 - accuracy: 0.9078 - val_loss: 0.3151 - val_accuracy: 0.9125\n",
      "Epoch 79/100\n",
      "1464/1500 [============================>.] - ETA: 0s - loss: 0.3308 - accuracy: 0.9083\n",
      "Epoch 79: val_loss improved from 0.31509 to 0.31471, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 866us/step - loss: 0.3309 - accuracy: 0.9082 - val_loss: 0.3147 - val_accuracy: 0.9127\n",
      "Epoch 80/100\n",
      "1452/1500 [============================>.] - ETA: 0s - loss: 0.3314 - accuracy: 0.9079\n",
      "Epoch 80: val_loss improved from 0.31471 to 0.31435, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 772us/step - loss: 0.3304 - accuracy: 0.9081 - val_loss: 0.3144 - val_accuracy: 0.9127\n",
      "Epoch 81/100\n",
      "1476/1500 [============================>.] - ETA: 0s - loss: 0.3301 - accuracy: 0.9082\n",
      "Epoch 81: val_loss improved from 0.31435 to 0.31396, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 755us/step - loss: 0.3299 - accuracy: 0.9083 - val_loss: 0.3140 - val_accuracy: 0.9126\n",
      "Epoch 82/100\n",
      "1465/1500 [============================>.] - ETA: 0s - loss: 0.3293 - accuracy: 0.9082\n",
      "Epoch 82: val_loss improved from 0.31396 to 0.31361, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 763us/step - loss: 0.3295 - accuracy: 0.9084 - val_loss: 0.3136 - val_accuracy: 0.9125\n",
      "Epoch 83/100\n",
      "1455/1500 [============================>.] - ETA: 0s - loss: 0.3283 - accuracy: 0.9085\n",
      "Epoch 83: val_loss improved from 0.31361 to 0.31325, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 773us/step - loss: 0.3290 - accuracy: 0.9084 - val_loss: 0.3133 - val_accuracy: 0.9128\n",
      "Epoch 84/100\n",
      "1456/1500 [============================>.] - ETA: 0s - loss: 0.3283 - accuracy: 0.9081\n",
      "Epoch 84: val_loss improved from 0.31325 to 0.31287, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 781us/step - loss: 0.3286 - accuracy: 0.9082 - val_loss: 0.3129 - val_accuracy: 0.9130\n",
      "Epoch 85/100\n",
      "1422/1500 [===========================>..] - ETA: 0s - loss: 0.3277 - accuracy: 0.9085\n",
      "Epoch 85: val_loss improved from 0.31287 to 0.31254, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 741us/step - loss: 0.3281 - accuracy: 0.9085 - val_loss: 0.3125 - val_accuracy: 0.9128\n",
      "Epoch 86/100\n",
      "1449/1500 [===========================>..] - ETA: 0s - loss: 0.3286 - accuracy: 0.9083\n",
      "Epoch 86: val_loss improved from 0.31254 to 0.31217, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 810us/step - loss: 0.3277 - accuracy: 0.9087 - val_loss: 0.3122 - val_accuracy: 0.9134\n",
      "Epoch 87/100\n",
      "1463/1500 [============================>.] - ETA: 0s - loss: 0.3274 - accuracy: 0.9090\n",
      "Epoch 87: val_loss improved from 0.31217 to 0.31183, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 949us/step - loss: 0.3272 - accuracy: 0.9089 - val_loss: 0.3118 - val_accuracy: 0.9133\n",
      "Epoch 88/100\n",
      "1477/1500 [============================>.] - ETA: 0s - loss: 0.3269 - accuracy: 0.9090\n",
      "Epoch 88: val_loss improved from 0.31183 to 0.31148, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 811us/step - loss: 0.3268 - accuracy: 0.9089 - val_loss: 0.3115 - val_accuracy: 0.9134\n",
      "Epoch 89/100\n",
      "1460/1500 [============================>.] - ETA: 0s - loss: 0.3258 - accuracy: 0.9090\n",
      "Epoch 89: val_loss improved from 0.31148 to 0.31115, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 792us/step - loss: 0.3264 - accuracy: 0.9091 - val_loss: 0.3111 - val_accuracy: 0.9135\n",
      "Epoch 90/100\n",
      "1473/1500 [============================>.] - ETA: 0s - loss: 0.3266 - accuracy: 0.9087\n",
      "Epoch 90: val_loss improved from 0.31115 to 0.31084, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3260 - accuracy: 0.9090 - val_loss: 0.3108 - val_accuracy: 0.9137\n",
      "Epoch 91/100\n",
      "1490/1500 [============================>.] - ETA: 0s - loss: 0.3253 - accuracy: 0.9095\n",
      "Epoch 91: val_loss improved from 0.31084 to 0.31052, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 789us/step - loss: 0.3256 - accuracy: 0.9094 - val_loss: 0.3105 - val_accuracy: 0.9136\n",
      "Epoch 92/100\n",
      "1481/1500 [============================>.] - ETA: 0s - loss: 0.3248 - accuracy: 0.9095\n",
      "Epoch 92: val_loss improved from 0.31052 to 0.31019, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 977us/step - loss: 0.3252 - accuracy: 0.9094 - val_loss: 0.3102 - val_accuracy: 0.9140\n",
      "Epoch 93/100\n",
      "1452/1500 [============================>.] - ETA: 0s - loss: 0.3250 - accuracy: 0.9094\n",
      "Epoch 93: val_loss improved from 0.31019 to 0.30986, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 887us/step - loss: 0.3248 - accuracy: 0.9095 - val_loss: 0.3099 - val_accuracy: 0.9142\n",
      "Epoch 94/100\n",
      "1486/1500 [============================>.] - ETA: 0s - loss: 0.3245 - accuracy: 0.9094\n",
      "Epoch 94: val_loss improved from 0.30986 to 0.30956, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 825us/step - loss: 0.3244 - accuracy: 0.9094 - val_loss: 0.3096 - val_accuracy: 0.9140\n",
      "Epoch 95/100\n",
      "1423/1500 [===========================>..] - ETA: 0s - loss: 0.3247 - accuracy: 0.9095\n",
      "Epoch 95: val_loss improved from 0.30956 to 0.30924, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 755us/step - loss: 0.3240 - accuracy: 0.9098 - val_loss: 0.3092 - val_accuracy: 0.9143\n",
      "Epoch 96/100\n",
      "1461/1500 [============================>.] - ETA: 0s - loss: 0.3245 - accuracy: 0.9097\n",
      "Epoch 96: val_loss improved from 0.30924 to 0.30896, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 775us/step - loss: 0.3236 - accuracy: 0.9098 - val_loss: 0.3090 - val_accuracy: 0.9142\n",
      "Epoch 97/100\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.3233 - accuracy: 0.9099\n",
      "Epoch 97: val_loss improved from 0.30896 to 0.30867, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 753us/step - loss: 0.3233 - accuracy: 0.9099 - val_loss: 0.3087 - val_accuracy: 0.9143\n",
      "Epoch 98/100\n",
      "1477/1500 [============================>.] - ETA: 0s - loss: 0.3238 - accuracy: 0.9098\n",
      "Epoch 98: val_loss improved from 0.30867 to 0.30836, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 807us/step - loss: 0.3229 - accuracy: 0.9101 - val_loss: 0.3084 - val_accuracy: 0.9143\n",
      "Epoch 99/100\n",
      "1482/1500 [============================>.] - ETA: 0s - loss: 0.3231 - accuracy: 0.9102\n",
      "Epoch 99: val_loss improved from 0.30836 to 0.30811, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 758us/step - loss: 0.3225 - accuracy: 0.9102 - val_loss: 0.3081 - val_accuracy: 0.9143\n",
      "Epoch 100/100\n",
      "1493/1500 [============================>.] - ETA: 0s - loss: 0.3223 - accuracy: 0.9102\n",
      "Epoch 100: val_loss improved from 0.30811 to 0.30781, saving model to ./model_optimization\\mnist_MLP.hdf5\n",
      "1500/1500 [==============================] - 1s 776us/step - loss: 0.3222 - accuracy: 0.9102 - val_loss: 0.3078 - val_accuracy: 0.9140\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, verbose=1, validation_split=0.2, callbacks=[early_stopping_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 552us/step - loss: 0.3076 - accuracy: 0.9157\n",
      "accuracy : 0.92\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "print(f\"accuracy : {round(score[1],2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_val_loss = history.history[\"val_loss\"]\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "x_len = np.arange(len(y_loss))\n",
    "\n",
    "plt.plot(x_len, y_val_loss, marker='.', c='red', label='Testset_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c='blue', label='Trainset_loss')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
